import asyncio
from twscrape import API, gather
from twscrape.logger import set_log_level
import mysql.connector as mysql
import sys,json
from datetime import datetime, timedelta
import time
import pytz

print('Connecting to the database...')

db = mysql.connect(user='', password='',host='',database='', port='')
cursor = db.cursor(buffered=True)

print('Connected to the database!\n')

valid_food = ['garÅ¡ot','garÅ¡oju','garÅ¡oÅ¡u','garÅ¡o','garÅ¡oji','garÅ¡osi','garÅ¡oja','garÅ¡os','garÅ¡ojot','garÅ¡otu','jÄgarÅ¡o','nogarÅ¡ot',
            'nogarÅ¡oju','nogarÅ¡oÅ¡u','nogarÅ¡o','nogarÅ¡oji','nogarÅ¡osi','nogarÅ¡oja','nogarÅ¡os','nogarÅ¡ojam','nogarÅ¡ojÄm','nogarÅ¡osim',
            'nogarÅ¡ojat','nogarÅ¡ojÄt','nogarÅ¡ojot','nogarÅ¡otu','pagarÅ¡ot','pagarÅ¡oju','pagarÅ¡oÅ¡u','pagarÅ¡o','pagarÅ¡oji','pagarÅ¡osi',
            'pagarÅ¡oja','pagarÅ¡os','pagarÅ¡ojam','pagarÅ¡ojÄm','pagarÅ¡osim','pagarÅ¡ojat','pagarÅ¡ojÄt','pagarÅ¡ojot','pagarÅ¡otu','Ä“du',
            'Ä“dÄ«Å¡u','Ä“d','Ä“di','Ä“dÄ«si','Ä“da','Ä“dÄ«s','Ä“dam','Ä“dÄm','Ä“dÄ«sim','Ä“dat','Ä“dÄt','Ä“dÄ«siet','Ä“d','Ä“dot','Ä“dÄ«Å¡ot','Ä“stu','jÄÄ“d',
            'apÄ“st','apÄ“du','apÄ“dÄ«Å¡u','apÄ“d','apÄ“di','apÄ“dÄ«si','apÄ“da','apÄ“dÄ«s','apÄ“dam','apÄ“dÄm','apÄ“dÄ«sim','apÄ“dat','apÄ“dÄt','apÄ“dÄ«siet',
            'apÄ“d','apÄ“dot','apÄ“dÄ«Å¡ot','apÄ“stu','atÄ“st','atÄ“du','atÄ“d','atÄ“d','ieÄ“st','ieÄ“du','ieÄ“dÄ«Å¡u','ieÄ“d','ieÄ“di','ieÄ“dÄ«si','ieÄ“da',
            'ieÄ“dÄ«s','ieÄ“dam','ieÄ“dÄm','ieÄ“dÄ«sim','ieÄ“d','ieÄ“dot','ieÄ“stu','izÄ“st','izÄ“du','izÄ“dÄ«Å¡u','izÄ“d','izÄ“di','izÄ“dÄ«si','izÄ“da',
            'izÄ“dÄ«s','izÄ“dam','izÄ“dÄm','izÄ“dÄ«sim','izÄ“dat','izÄ“dÄt','izÄ“dÄ«siet','izÄ“d','izÄ“stu','neÄ“st','neÄ“du','neÄ“dÄ«Å¡u','neÄ“di',
            'neÄ“dÄ«si','neÄ“da','neÄ“dÄ«s','neÄ“dam','neÄ“dÄm','neÄ“dÄ«sim','neÄ“dat','neÄ“dÄt','neÄ“d','neÄ“dot','neÄ“dÄ«Å¡ot','neÄ“stu','noÄ“st','noÄ“du',
            'noÄ“dÄ«Å¡u','noÄ“d','noÄ“di','noÄ“dÄ«si','noÄ“da','noÄ“dÄ«s','noÄ“dam','noÄ“dÄm','noÄ“dÄ«sim','noÄ“d','noÄ“dot','noÄ“stu','paÄ“st','paÄ“du',
            'paÄ“dÄ«Å¡u','paÄ“d','paÄ“di','paÄ“dÄ«si','paÄ“da','paÄ“dÄ«s','paÄ“dam','paÄ“dÄm','paÄ“dÄ«sim','paÄ“dat','paÄ“dÄt','paÄ“d','paÄ“dot','paÄ“stu',
            'uzÄ“st','uzÄ“du','uzÄ“dÄ«Å¡u','uzÄ“d','uzÄ“di','uzÄ“dÄ«si','uzÄ“da','uzÄ“dÄ«s','uzÄ“dam','uzÄ“dÄm','uzÄ“dÄ«sim','uzÄ“dat','uzÄ“dÄt','uzÄ“dÄ«siet',
            'uzÄ“d','uzÄ“dot','uzÄ“stu','saÄ“sties','saÄ“dos','saÄ“dÄ«Å¡os','saÄ“dies','saÄ“dÄ«sies','saÄ“das','saÄ“dÄs','saÄ“dÄ«sies','saÄ“damies',
            'saÄ“dÄmies','saÄ“dÄ«simies','saÄ“daties','saÄ“dÄties','saÄ“doties','saÄ“stos','jÄsaÄ“das','pÄrÄ“sties','pÄrÄ“dos','pÄrÄ“dÄ«Å¡os','pÄrÄ“dies',
            'pÄrÄ“dÄ«sies','pÄrÄ“das','pÄrÄ“dÄs','pÄrÄ“dÄ«sies','pÄrÄ“damies','pÄrÄ“dÄmies','pÄrÄ“dÄ«simies','pÄrÄ“doties','pÄrÄ“stos','pieÄ“sties',
            'pieÄ“dos','pieÄ“dÄ«Å¡os','pieÄ“dies','pieÄ“dÄ«sies','pieÄ“das','pieÄ“dÄs','pieÄ“dÄ«sies','pieÄ“damies','pieÄ“dÄmies','pieÄ“dÄ«simies',
            'pieÄ“doties','pieÄ“stos','brokastot','brokastoju','brokastoÅ¡u','brokasto','brokastoji','brokastosi','brokastoja','brokastos',
            'brokastojam','brokastojÄm','brokastosim','brokastojat','brokastojÄt','brokastojot','jÄbrokasto','pusdienot','pusdienoju',
            'pusdienoÅ¡u','pusdieno','pusdienoji','pusdienosi','pusdienoja','pusdienos','pusdienojam','pusdienojÄm','pusdienosim',
            'pusdienojat','pusdienojÄt','pusdienojot','pusdienotu','jÄpusdieno','vakariÅ†ot','vakariÅ†oju','vakariÅ†oÅ¡u','vakariÅ†o',
            'vakariÅ†oji','vakariÅ†osi','vakariÅ†oja','vakariÅ†os','vakariÅ†ojam','vakariÅ†ojÄm','vakariÅ†osim','vakariÅ†ojot','iekoÅ¾u',
            'iekodÄ«Å¡u','iekodÄ«si','iekoÅ¾','iekoda','iekodÄ«s','iekoÅ¾am','iekodÄm','iekodÄ«sim','iekoÅ¾ot','iekostu','jÄiekoÅ¾','uzkoÅ¾u',
            'uzkodu','uzkodÄ«Å¡u','uzkodÄ«si','uzkoÅ¾','uzkodÄ«s','uzkoÅ¾am','uzkodÄm','uzkodÄ«sim','uzkoÅ¾at','maltÄ«te','garÅ¡Ä«gs','garÅ¡Ä«ga',
            'kÄrums','Å†am','Å†amma','apetÄ«te','Ä“diens','brokastis','pusdienas','vakariÅ†as','brokastÄ«s','pusdienÄs','vakariÅ†Äs','launagÄ',
            'Ä“st','Ä“dis','Ä“dusi','notiesÄju','notiesÄÅ¡u','notiesÄt','mandarÄ«nus','saldÄ“jumu','tÄ“ju','pankÅ«kas','Å¡okolÄdi','Å¡okolÄdes',
            'kÅ«ku','ÄipÅ¡us','kafija','tÄ“ja','gaÄ¼u','konÄÄs','pelmeÅ†us','piparkÅ«kas','maizÄ«tes','mÄ“rci','Äbolu','gaÄ¼as','kartupeÄ¼u',
            'Å¡okolÄde','salÄtus','saldumus','hesÄ«tÄ«','mandarÄ«nu','kÅ«kas','kartupeÄ¼us','mÄ“rce','tomÄtu','mandarÄ«ni','pelmeÅ†i','ApelsÄ«nu',
            'DÄrzeÅ†u','salÄti','saldÄ“juma','SaldÄ“jums','kartupeÄ¼iem','tÄ“jas','maÄ·Ä«tÄ«','krÄ“mzupa','KÄrums','bulciÅ†as','salÄtiem','zemeÅ†u',
            'piparkÅ«ku','maizÄ«ti','tÄ“jiÅ†u','kÅ«ciÅ†u','kÄpostu','Äipsi','sÄ«polu','vÄ«nogas','krÄ“jumu','bieÅ¡u','burkÄnu','rÄ«siem','dÄrzeÅ†iem',
            'sÄ“nes','degustÄ“ju','degustÄ“t','degustÄ“Å¡u','griÄ·i','griÄ·us','griÄ·iem','griÄ·u','griÄ·os','rÄ«si','rÄ«sus','rÄ«Å¡u','pierÄ«ties',
            'pusdienÄs','brokastÄ«s','vakariÅ†Äs','garÅ¡Ä«gi','kafiju','Ä“dienu','dzÄ“riens','garÅ¡Ä«gas','mÄ“rcÄ“','paÄ“stas','zemenes','paÄ“dÄm',
            'cÅ«kgaÄ¼as','kafijas','Ä“dis','apetÄ«ti','garÅ¡u','kotletes','negarÅ¡o','garÅ¡Ä«gu','biezpiena','konÄas','sÄ“Å†u','Ä“dÄm','banÄnu',
            'konfektes','Äipsus','jÄpaÄ“d','karbonÄde','tomÄtiem','salÄtu','sautÄ“jums','suÅ¡i','biezpienu','pÄ«rÄgs','garÅ¡a','krÄ“juma',
            'brokastu','garÅ¡as','Ä“diena','pusdienÄm','Ä·irbju','karameÄ¼u','zirÅ†u','skÄbeÅ†u','vaniÄ¼as','zemenÄ“m','Ä·irÅ¡u','gurÄ·i','dÄrzeÅ†i',
            'aveÅ†u','ievÄrÄ«jumu','putukrÄ“jumu','Ä“dieni','pÄrtiku','gurÄ·u','Ä·iploku','Ä“Å¡anas','Äbolus','augÄ¼iem','arbÅ«zu','laÅ¡a','kefÄ«rs',
            'tomÄti','Ä“dienus','cÅ«kgaÄ¼a','banÄnus','banÄni','vakariÅ†Äm','dÄrzeÅ†us','brokastÄ«m','augÄ¼us','dzerÅ¡u','cÅ«kgaÄ¼u','pankÅ«ku',
            'majonÄ“zi','olÄm','upeÅ†u','karbonÄdes','kabaÄu','apÄ“dÄm','jÄiedzer','sÄ«poliem','kÅ«ciÅ†as','Äboliem','pankÅ«kÄm','paÄ“dis',
            'mÄ“rcÄ«ti','Äboli','biezzupa','biezpiens','spinÄtu','karbonÄdi','pupiÅ†as','grauzdiÅ†iem','melleÅ†u','Ä“dieniem','pupiÅ†Äm',
            'gardÄs','Äbols','burkÄnus','Ä·Ä«seli','burkÄniem','gulaÅ¡s','kÄpostiem','tomÄtus','jÄizdzer','kumelÄ«Å¡u','plÄcenÄ«Å¡i','Å¡Ä·iÅ†Ä·i',
            'gurÄ·iem','banÄniem','gurÄ·us','dzÄ“rveÅ†u','tostermaizes','zupiÅ†a','Å¡aÅ¡liku','tÄ«tara','Ä·irÅ¡us','cÄ«siÅ†us','bulciÅ†u','burkÄni',
            'aliÅ†u','gaileÅ†u','Å¡ampinjonu','krÄ“jums','pankÅ«ciÅ†as','aliÅ†Å¡','cÄÄ¼a','tÄ«teÅ†i','Ä“Å¡ana','ribiÅ†as','mÄ“rces','zupiÅ†u','borÅ¡Äs',
            'brokastiÅ†as','kÄposti','sieriÅ†u','Å¡Å†abi','siÄ¼Ä·i','ogÄm','garÅ¡Ä«gÄs','garÅ¡Ä«go','ananÄsu','pieÄ“dÄmies','ievÄrÄ«jums','speÄ·i',
            'sÄ«rupu','kukurÅ«zu','Ä“dienreizes','maizÄ«te','pÄ«rÄdziÅ†i','pÄ«rÄgu','nÅ«deles','saldÄ“jumus','jÄpadzer','pÄ«rÄdziÅ†us','vistiÅ†u',
            'sÄ«polus','banÄns','kefÄ«ru','sÄ«poli','zirÅ†i','salÄtiÅ†iem','kÄpostus','sautÄ“jumu','tunÄa','zirÅ†us','Å¡ampinjoniem','Å¡protes',
            'pÄrÄ“dusies','desiÅ†as','zirnÄ«Å¡u','garÅ¡Ä«gus','spinÄtiem','tomÄts','cepumiÅ†us','garnelÄ“m','pelmeÅ†iem','Å¡Å†abis','izdzerÅ¡u',
            'Ä·iplokus','Äipsu','kukurÅ«zas','pustdienas','mandeÄ¼u','salÄtiÅ†i','rozÄ«nÄ“m','Å¡okolÄdÄ“','mandarÄ«niem','dzÄ“rvenes','salÄtiÅ†us',
            'cÄ«siÅ†i','grauÅ¾u','apelsÄ«nus','apÄ“stas','rupjmaizes','pÄ«rÄgus','ananÄsiem','apÄ“dis','siÄ¼Ä·e','Ä·irbi','majonÄ“ze','vakariÅ†u',
            'gardÄ','rozÄ«nes','Ä“dams','konfekÅ¡u','sviestmaizes','vistiÅ†as','rupjmaizi','tÄ“jiÅ†a','Äipsiem','maizÄ«tÄ“m','Ä“dienreize',
            'biezputru','kefÄ«ra','apÄ“sts','zirnÄ«Å¡iem','garÅ¡Ä«gÄks','padzerÅ¡u','vafeÄ¼u','sieriÅ†Å¡','tefteÄ¼i','mÄ“rcÄ«te','pÄ«rÄgi','pelmeÅ†u',
            'Ä·irÅ¡i','uzÄ“dÄm','desmaizes','gurÄ·Ä«Å¡us','negarÅ¡oja','virtuÄ¼us','krÄ“mzupu','kotletÄ“m','kabaÄi','olÄ«vas','Å¡nicele','karstvÄ«ns',
            'zupÄ','salÄtos','kÅ«kÄm','brÅ«kleÅ†u','Å¡Ä·iÅ†Ä·Ä«Å¡i','sviestmaizi','cepumiÅ†i','sieriÅ†us','Å¡ampanietis','diÄ¼Ä¼u','Ä·iploki','dzÄ“rienu',
            'konfektÄ“m','pankÅ«ka','burkÄns','garneÄ¼u','pÄrslÄm','plÅ«mes','greipfrÅ«tu','Ä“dienam','Ä·Ä«selis','laÅ¡maizÄ«tes','rupjmaize',
            'siermaizÄ«tes','avenÄ“m','piparkÅ«kÄm','grauzdiÅ†us','siermaizes','pabarot','Ä“Å¡anu','pieÄ“dies','ÄipÅ¡i','soÄ¼anku','Ä“dienkartÄ“',
            'koÅ†Äas','nÅ«delÄ“m','apÄ“dusi','kÅ«ciÅ†a','majonÄ“zes','mellenÄ“m','vistiÅ†a','Ä·irÅ¡iem','augÄ¼i','riekstiÅ†us','apelsÄ«ni','kartupelÄ«Å¡i',
            'late','latte','lates','lattes','kapuÄino','kapuÄÄ«no']

spammers = ['berelilah_jpg', 'Twitediens', 'dievietelv', 'CrabstickFusion', 'oreotsuka', 'pingwsie', 'taunlts']

def is_dst(zonename):
    tz = pytz.timezone(zonename)
    now = pytz.utc.localize(datetime.utcnow())
    return now.astimezone(tz).dst() != timedelta(0)

def clean_text(text):

    text = text.replace("\n", " ")
    text = text.replace("\t", " ")
    text = text.replace("<br>", " ")
    text = text.replace("</br>", " ")
    text = text.replace("-", " ")
    text = text.replace(",", " ")
    text = text.replace(";", " ")
    text = text.replace(":", " ")
    text = text.replace(".", " ")
    text = text.replace("/", " ")
    text = text.replace("]", " ")
    text = text.replace("[", " ")
    text = text.replace(")", " ")
    text = text.replace("(", " ")
    text = text.replace("!", " ")
    text = text.replace("?", " ")
    text = text.replace("'", " ")
    text = text.replace('"', ' ')
    text = text.replace('#', " ")
    text = text.replace("  ", " ")

    return text

def trashy_count(text):
    badChars = ["ğ“ª","ğª","Äƒ","Ã¥","ğ›¼","ğš","Ã ","Ã¡","Ã¤","Ã†","Ã¦","Ç£","Î±","ğ—®","ğœ¶","ï½","ğ’‚","Ã¢","ğ˜¢","ğ—”","Èƒ","Ãƒ","Ã£",
                "Æ„",
                "Ä","ğ—±","ğ–£","ğ“­","ğ’…","ğ","ğ——",
                "Ä™","Ä˜","È©","ğ","ğ—²","ğ‘’","ï½…","È…","Ò½","Ã«","ğ™š","ğ˜¦","Ä›","Ãª","ğ”¢","Ã©","Ä•","Ã¨","ğ—˜","ğ’†",
                "ğ–¿","ğ’‡","ğ˜§","ğ—³","áº","ğ‘“",
                "Ä¡","Ç§",
                "ğ¡","ğ™","ğ”¥","Ä§",
                "Ä¨","Èˆ","Ä°","Ä¬","Ä®","ğš¤","ê­µ","Ã®","Ã","ğ–","Ç","Ä¯","Ã­","Ã","Ä±",
                "ğ™ ","ğ’Œ","ğ¤","ğ—¸",
                "È¯","Ã²","Å","È«","ğ¾","ğ—¼","ğ¸","ğ¨","Ãµ","È­","Ã³","Ã¸","Ã¶","Ã˜","ğ™¤","Ç’","á€","ğ˜°","ğ’","ğ—ˆ","Ã”","Ã°",
                "Å€","ğŒ ",
                "á—°","ğ—º",
                "Å‰","ğ–“","ğ§","ğ—»","Ã±","Ç¹","ğ˜¯","ğ—‡","Å„","ğ‘›",
                "ğ›’","ğ—£","ğ—½",
                "ğ«","ğ”¯","ğ—¿",
                "ğ˜","Å§","È›","ğ–™","ğ’•","ğ—§",
                "ğ˜€","Å","ğ‘ ","ğ’”","Æ½","Å›","È™","ğ“ˆ",
                "È—","Ç–","Çœ","È•","Å±","ğ™ª","ğ„","Ã»","Ãº","Ã¼","Å³","Å­","Ç˜","ğ—¨","ğ›–","Ã™",
                "ğ’˜","ğ“¦","Ñ¡","ğ˜„","Å´","ğ™¬","ğ—ª",
                "ğ”","ğ˜¹",
                "Ã¿","Ñ‡","ğ›¾","È³","Å·","ğ’š",
                "ÃŸ",
                "ğ“ˆŠ","ğ“‹²",
                "Ø¡","ØŒ","Ø®","Ø§","Ù","Ø«","Ù‹","ØŒ","Ø´","Ø±","Ø¶","Ùˆ","Ù…","Ù‚","Ø¹","Ø²","Ø©","ØŒ","Ø¥","Ø³","Ø¦","Ù„","Ùƒ","Ù†","ÙŠ","Ø£","Ø­","Ø¨","Øª","Ù‡"]
    trashy = 0
    for char in badChars:
        if char in text:
            trashy+=1

    return trashy

def  remove_mentions(text):
    # Count of all mentions
    atcount = text.count("@")
    # Position of last mention
    if atcount > 0:
        position = text.rindex("@")
        # Trim if more than 10 mentions...
        if atcount > 10 or len(text) > 450:
            text = text[position:]
    return text

def add_tweet(id, text, screen_name, created_at, geo, quoted = None):
    if quoted == None:
        sql = "INSERT IGNORE INTO tweets (id ,text ,screen_name, created_at, geo) VALUES (%s, %s, %s, %s, %s)"
        val = (id, text, screen_name, created_at, geo)
    else:
        sql = "INSERT IGNORE INTO tweets (id ,text ,screen_name, created_at, geo, quoted_id) VALUES (%s, %s, %s, %s, %s, %s)"
        val = (id, text, screen_name, created_at, geo, quoted)
    cursor.execute(sql, val)

def add_word(vards, nominativs, tvits, grupa, eng, datums):
    sql = "INSERT IGNORE INTO words (vards, nominativs, tvits, grupa, eng, datums) VALUES (%s, %s, %s, %s, %s, %s)"
    val = (vards, nominativs, tvits, grupa, eng, datums)
    cursor.execute(sql, val)

def add_media(tweet_id, media_url, date):
    sql = "INSERT IGNORE INTO media (tweet_id, media_url, date) VALUES (%s, %s, %s)"
    val = (tweet_id, media_url, date)
    cursor.execute(sql, val)
    # print('Media added?\n')

def add_mention(screen_name, tweet_id, mention, date):
    sql = "INSERT IGNORE INTO mentions (screen_name, tweet_id, mention, date) VALUES (%s, %s, %s, %s)"
    val = (screen_name, tweet_id, mention, date)
    cursor.execute(sql, val)

def save_tweet(tweet, recent_ids, food_names):

    # Format the date
    tweetDate = tweet['date']
    if is_dst("Europe/Riga"):
        hourdiff = 3
    else:
        hourdiff = 2

    if str(tweetDate)[-6:] == '+00:00':
        DBformat = "%Y-%m-%d %H:%M:%S"
        real_time = tweetDate + timedelta(hours=hourdiff)
        LVdate = format(real_time, DBformat)

    if tweet['user']['username'] not in spammers:
        # Maybe insert in DB from here
        quoted_id = None
        if tweet['quotedTweet'] is not None:
            # Insert if does not exist yet
            # select = "SELECT id FROM tweets where id = %s"
            # value = (quoted_id,)
            # cursor.execute(select, value)

            # if cursor.rowcount == 0:
            if quoted_id not in recent_ids:
                saved_quote = save_tweet(tweet['quotedTweet'], recent_ids, food_names)
                if saved_quote:
                    quoted_id = tweet['quotedTweet']['id']

        # attÄ«ra
        tweet_text = tweet['rawContent']
        ntext = clean_text(tweet_text);
        tc = trashy_count(tweet_text);
        edieni = 0;

        if len(ntext)>0:
            vardi = ntext.split()
            edienVardi = []
            RLYsave = False
            for vards in vardi:

                vards = vards.replace("  ", "")
                vards = vards.replace(" ", "")
                vards = vards.replace("-", "")
                vards = vards.replace("'", "")
                vards = vards.replace('"', '')

                if len(vards) > 2 and vards[0:4]!='http' and not any(char.isdigit() for char in vards) and not any(substring in vards for substring in ['@','#','\n','\r']):
                    edienVardi.append(vards)
                    if vards in valid_food:
                        RLYsave = True

            # Skip saving at this point if no food words actually found in the text
            if not RLYsave:
                return False

            myset = set(edienVardi)
            edienVardi = list(myset)

            for edienvards in edienVardi:

                # select = "SELECT nominativs, grupa, eng FROM words WHERE tvits != %s AND LOWER(CAST(vards AS CHAR CHARACTER SET utf8)) = LOWER(CAST(%s AS CHAR CHARACTER SET utf8)) LIMIT 1"
                # value = (tweet['id'], edienvards)
                # cursor.execute(select, value)
                # if cursor.rowcount > 0:
                #     results = cursor.fetchall()
                ev = edienvards.lower()

                if ev in food_names:

                    nom = food_names[ev]["nom"]
                    gru = food_names[ev]["gru"]
                    eng = food_names[ev]["eng"]

                    edieni+=1

                    add_word(edienvards, nom, tweet['id'], gru, eng, LVdate)

            retweet = tweet_text[0:4] == "RT @";

            if RLYsave and not retweet and (edieni > 0 or tweet_text[0]=="@" or tc < 3):

                insert_text = remove_mentions(tweet_text)

                if tweet['place'] is not None:
                    if tweet['place']['name'] is not None:
                        geo = tweet['place']['name']
                else:
                    geo = None

                add_tweet(tweet['id'], insert_text, tweet['user']['username'], LVdate, geo, quoted_id)

                for photo in tweet['media']['photos']:
                    add_media(tweet['id'], photo['url'], LVdate)
                for user in tweet['mentionedUsers']:
                    add_mention(tweet['user']['username'], tweet['id'], user['username'], LVdate)

                db.commit()
                return True


async def main():
    api = API()  # or API("path-to.db") - default is `accounts.db`

    await api.pool.add_account("USERNAME", "PASSWORD", "EMAIL", "_")
    await api.pool.add_account("USERNAME", "PASSWORD", "EMAIL", "_")
    await api.pool.add_account("USERNAME", "PASSWORD", "EMAIL", "_")
    await api.pool.add_account("USERNAME", "PASSWORD", "EMAIL", "_")
    await api.pool.add_account("USERNAME", "PASSWORD", "EMAIL", "_")
    await api.pool.add_account("USERNAME", "PASSWORD", "EMAIL", "_")
    await api.pool.add_account("USERNAME", "PASSWORD", "EMAIL", "_")
    await api.pool.login_all()

    set_log_level("DEBUG")

    # Tweet & User model can be converted to regular dict or json, e.g.:

    # 28 most common keywords with the highest hit-rate    
    keywords = ["Ä“du", "Ä“d", "Ä“dam", "Ä“st", "paÄ“st", "garÅ¡o", "pusdieno", "vakariÅ†o", "brokasto", "pusdienas",
                 "vakariÅ†as", "brokastis", "Å¡okolÄde", "gaÄ¼a", "Ä“diens", "kartupeÄ¼u", "pankÅ«ka", "salÄti", 
                 "Äbolu", "kÅ«ku", "Å†am", "saldÄ“jums", "tomÄtu", "mÄ“rci", "garÅ¡Ä«gs", "dÄrzeÅ†u", "Ä“dÄ«Å¡u", "saldÄ“jumu"]

    # 22 next most common keywords with a high hit-rate    
    more_keywords = ["kafija", "tÄ“ja", "paÄ“d", "tÄ“ju", "apÄ“d", "kÅ«kas", "tÄ“jas", "paÄ“du", "apÄ“st", "Ä“dÄ«s", 
                    "garÅ¡Ä«ga", "neÄ“d", "apÄ“du", "mandarÄ«nu", "saldumus", "maizÄ«tes", "pelmeÅ†us", "zemeÅ†u",
                    "Ä“dot", "dÄrzeÅ†iem", "mandarÄ«ni", "salÄtus"]

    # 21 further most common keywords with a good hit-rate    
    even_more_kw = ["Ä“dusi", "kÄpostu", "kartupeÄ¼iem", "Ä“dis", "garÅ¡ot", "ieÄ“d", "apÄ“da", "piparkÅ«kas", 
                    "mandarÄ«nus", "jÄÄ“d", "Ä“stu", "pelmeÅ†i", "uzÄ“d","sÄ“nes", "Ä“dÄ«si", "pusdienÄs", 
                    "brokastÄ«s","vakariÅ†Äs","Ä“dÄm", "kartupeÄ¼us", "Ä“dÄ«sim"]

    kw_groups = [keywords, more_keywords, even_more_kw]

    recent_max = 5000

    if(len(sys.argv) > 1):
        k_from  = sys.argv[1] # "2024-01-01"
        k_to    = sys.argv[2] # "2024-01-27" 
        recent_max = 40000
    else:
        tomorrow = datetime.now() + timedelta(1)
        yesterday = datetime.now() - timedelta(1)
        today = datetime.now()

        k_from = datetime.strftime(yesterday, '%Y-%m-%d')
        k_to = datetime.strftime(tomorrow, '%Y-%m-%d')
    # Maybe needs day+1 to get tweets from the day

    print("Searching for tweets between "+ k_from + " and " + k_to)

    # Before inserting any tweets, select the last... 5000 inserted tweet IDs, keep the list in memory and only insert if not in list
    recent_ids = []
    tweet_id_select = "SELECT id FROM `tweets` ORDER BY created_at DESC LIMIT 0, " + str(recent_max)
    cursor.execute(tweet_id_select)
    for result in cursor:
        recent_ids.append(result[0])

    print("Got " + str(len(recent_ids)) + " recent tweet IDs for double-checking.")

    # Now do the same for the ~2000 food names
    food_names = {}
    food_name_select = "SELECT DISTINCT LOWER(CAST(vards AS CHAR CHARACTER SET utf8)) as vards, nominativs, grupa, eng FROM `words` ORDER BY vards; "
    cursor.execute(food_name_select)
    for result in cursor:
        food_names[result[0]] = {"nom":result[1], "gru":result[2], "eng":result[3]}

    print("Got " + str(len(food_names)) + " food names for double-checking.")

    added_count = 0

    for kw_group in kw_groups:
        keywordstring = ' OR '.join(kw_group)

        doc = await gather(api.search(keywordstring+" lang:lv -filter:nativeretweets since:"+k_from+" until:"+k_to, limit=3200, kv={"product": "Latest"}))

        print("Found " + str(len(doc)) + " tweets. Processing...")
        

        # with open('tweet-data-now.json', 'w', encoding='utf-8') as f:
        #     for entry in doc:
        #         # json.dump(entry.json(), f, ensure_ascii=False, indent=2)
        #         string = json.dumps(entry.json(), ensure_ascii=True, indent=2)
        #         f.write(string + "\n")

        for entry in doc:
            tweet = entry.dict()

            # Before inserting any tweets, select the last... 5000 inserted tweet IDs, keep the list in memory and only insert if not in list

            if tweet['id'] not in recent_ids:
                saved = save_tweet(tweet, recent_ids, food_names)
                if saved:
                    added_count += 1

        time.sleep(20)

    print("Saved " + str(added_count) + " new tweets.")


if __name__ == "__main__":
    asyncio.run(main())